{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free App Profiles Likely to Generate Profit in the App Store and Google Play \n",
    "\n",
    "   This project will document an attempt to use python and data analysis to determine what makes an app \"attractive\" to a consumer. Working within a specific client-base of English-speakers who do not pay for phone apps, first all non-English and non-free apps will be removed. Once purged of defects and undesirable app types, the number of downloads and ratings, and average user ratings of the remaining apps will be extracted. Taking this data and examining the differences across genres will help provide a guideline for determining which categories of apps are deemed to have higher potential for ad-revenue. We will be using data from ~10,000 Google Play apps and ~7,000 iOS apps collected in 2018 and 2017 respectively.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types and Exploration\n",
    "As of August 2020, the Google Play store had roughly 2.7 million apps on it, and the iOS app store had roughly 1.8 million. Given such large amounts of data would take significantly longer to work through and might cost more to acquire all of it than would be worth, we will take a smaller subset of data, this being the aforementioned datasets collected in 2018 and 2017. \n",
    "\n",
    "- [Google Play Store data](https://www.kaggle.com/lava18/google-play-store-apps): Roughly 10,000 **Android** apps compiled in 2018. [Download here](https://dq-content.s3.amazonaws.com/350/googleplaystore.csv)\n",
    "- [App Store data](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps): Roughly 7,000 **iOS** apps compiled in 2017. [Download here](https://dq-content.s3.amazonaws.com/350/AppleStore.csv)\n",
    "\n",
    "The first step will be opening and exploring the dataset. The function below will be used to check datasets to ensure they're correct. The `explore_data()` function takes four parameters and prints out relevant data. The parameters are such:\n",
    "\n",
    "- `dataset`: This takes in the dataset that we want to explore.\n",
    "- `start`: This designates the beginning of the slice.\n",
    "- `end`: This designates the index **after** the last visible index in the slice. \n",
    "- `rows_and_columns=False`: This parameter defaults to **False** as shown, but if assigned **True** it will output the number of rows and columns in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll take each data set, open them, assign them to a local list, and check that they're both intact datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10842\n",
      "Number of columns: 13\n",
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7198\n",
      "Number of columns: 16\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "# Opening the Google Play data and storing it to a local list\n",
    "open_file_2 = open('googleplaystore.csv', encoding='utf8')\n",
    "read_file_google = reader(open_file_2)\n",
    "google_data = list(read_file_google)\n",
    "\n",
    "# Opening the Apple Store data and storing it to a local list\n",
    "open_file_1 = open('AppleStore.csv', encoding='utf8')\n",
    "read_file_apple = reader(open_file_1)\n",
    "apple_data = list(read_file_apple)\n",
    "\n",
    "# Check that each dataset came out by checking their headers against a line of specific data.\n",
    "explore_data(google_data, 0,2, True)\n",
    "explore_data(apple_data, 0,2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "\n",
    "Before using the datasets for our purposes, it must be 'cleaned' or purged of incorrect or extraneous data, and what can be corrected must be corrected. In addition to that, given the additional constraints of what we're looking for--free apps for English-speakers--we must purge any data that doesn't match those conditions. \n",
    "\n",
    "### I. Format Checking\n",
    "\n",
    "First we'll take the length of the header of each file by using the `len()` command on each dataset and assigning its integer value to a variable `name_head_len` where `name` is `goog` or `ios`where it ought to be. Then using that number we'll remove any data lines that do not have the correct length (and therefore do not have all of the relevant information and need not be considered). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "goog_head_len = len(google_data[0])\n",
    "ios_head_len = len(apple_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will define a function to check data length against a desired length and print the row and index of any row that does not have the correct amount of data. The `len_check` code works by taking a `dataset` and desired `length` as its parameters, and runs each `row` in the `dataset` through an `if` statement to confirm its length. If it doesn't match, the function will print the row and index of the incorrect data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_check(dataset,length):\n",
    "    for row in dataset:\n",
    "        row_length = len(row)\n",
    "        if row_length != length:\n",
    "            print(row)\n",
    "            print(dataset.index(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_check(google_data,goog_head_len)\n",
    "len_check(apple_data,ios_head_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find one line from the **Google Play Store** (we can tell where it's from by checking it against the headers we printed above) that doesn't match. In order to prevent this incorrect line from corrupting our analysis, we will delete this row with the line `del google_data[10473]` which is run once and then removed so as to avoid deleting the wrong data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del google_data[10473]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Checking for and Eliminating Duplicates Chronologically\n",
    "\n",
    "Using the number of total reviews for each app, found in column `3` and `5` for the **App Store** and the **Google Play Store** repectively, we will check for duplicate names and retain only the `row` with the highest number of ratings (and is therefore the most recent data).\n",
    "\n",
    "#### Step 1: Identifying Unique App Names\n",
    "The first step will be creating a dictionary with a `name:index` format, of unique apps with the highest ratings. The function below, `name_maxreview_dictionary()` takes the following four parameters:\n",
    "\n",
    "- `dataset` : The dataset to be trimmed.\n",
    "- `namecol` : The column for names\n",
    "- `revnumcol` : The column for max reviews\n",
    "- `header = True` : Whether the dataset has a header (defaults to **True**)\n",
    "\n",
    "The function takes four arguments and generates a dictionary with each row, and if it has the name (`key`) already exists in the dictionary, it only updates the `definition` if the `revnumcol` value is higher than the original `definition`. It then outputs a dictionary with the unique names and their highest review number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_maxreview_dictionary(dataset, namecol, revnumcol, header = True):\n",
    "    nr_Dict = {}\n",
    "    if header == True:\n",
    "        for row in dataset[1:]:\n",
    "            name = row[namecol]\n",
    "            n_reviews = float(row[revnumcol])\n",
    "            if name in nr_Dict and n_reviews > nr_Dict[name]:\n",
    "                nr_Dict[name] = n_reviews\n",
    "            if name not in nr_Dict:\n",
    "                nr_Dict[name] = n_reviews\n",
    "        return nr_Dict\n",
    "    if header == False:\n",
    "        for row in dataset:\n",
    "            name = row[namecol]\n",
    "            n_reviews = float(row[revnumcol])\n",
    "            if name in nr_Dict and n_reviews > nr_Dict[name]:\n",
    "                nr_Dict[name] = n_reviews\n",
    "            if name not in nr_Dict:\n",
    "                nr_Dict[name] = n_reviews\n",
    "        return nr_Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create two dictionaries, one for each dataset, and run them through the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Play data\n",
    "goog_reviews_max = {}\n",
    "goog_reviews_max = name_maxreview_dictionary(google_data,0,3)\n",
    "\n",
    "# Apple Store data\n",
    "apple_reviews_max ={}\n",
    "apple_reviews_max = name_maxreview_dictionary(apple_data,1,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Trimming the Data of Duplicates\n",
    "The next step will be to create a function that will trim the data using a dictionary key and output it to a new list. The function `dictionary_trim()` takes the following four parameters:\n",
    "- `dataset` : Dataset to be trimmed\n",
    "- `dictionary` : Dictionary to use as a 'stencil' for trimming.\n",
    "- `namecol` : Column to match against dictionary key\n",
    "- `totrevcol` : Column to match against dictionary key's relative definition.\n",
    "\n",
    "It takes each `dataset[namecol]` and checks the dictionary for the `key` with the same name. When it finds the `key` it checks the `definition` to see if it matches `dataset[totrevcol]` if it does and hasn't already been added, we add it to the `trimmed list`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_trim(dataset, dictionary, namecol, totrevcol):\n",
    "    trimmed_data = []\n",
    "    added_list = []\n",
    "    for row in dataset:\n",
    "        name = row[namecol]\n",
    "        n_reviews = float(row[totrevcol])\n",
    "        if name in dictionary and dictionary[name] == n_reviews and name not in added_list:\n",
    "            trimmed_data.append(row)\n",
    "            added_list.append(name)\n",
    "    return trimmed_data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run this function to print to two new lists: `android_clean` and `apple_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_clean =[]\n",
    "apple_clean = []\n",
    "\n",
    "\n",
    "android_clean = dictionary_trim(google_data[1:],goog_reviews_max,0,3)\n",
    "apple_clean= dictionary_trim(apple_data[1:],apple_reviews_max,1,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Purging non-English Apps \n",
    "\n",
    "Our project is only focused on free, English-language apps, so we can remove any apps whose titles are not in English.\n",
    "\n",
    "#### Step 1: Creating a True/False Dictionary\n",
    "We start by defining a function `char_check()` to determine how many non-standard characters are present in the title. Standard English characters in ASCII are defined numerically between 0 and 127, which can be found through the built-in `ord()` function.\n",
    "\n",
    "The function `char_check` takes up to three parameters:\n",
    "\n",
    "- `string` : The string to be checked, for example the app title name.\n",
    "- `minrange`: The minimum character number.\n",
    "- `maxrange`: The maximum character number.\n",
    "\n",
    "As we can see, this function allows the input of any character range, but it defaults to the English range (0-127). The `char_check()` function takes the `string` and checks each `char` (character) in the string for its `ord()` number, and then if it's outside of the specified range, it adds a tally to the `outofbounds_char` variable. If that variable goes over `3`, we consider the app to have too many foreign characters, and it returns `False`, otherwise it returns `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_check(string, minrange=0, maxrange=127):\n",
    "    outofbounds_char_tally = 0\n",
    "    for char in string:\n",
    "        if ord(char) > maxrange or ord(char)<minrange:\n",
    "            outofbounds_char_tally += 1\n",
    "            if outofbounds_char_tally >3:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `eng_clean` will take two parameters:\n",
    "- `dataset` : The dataset we're cleaning \n",
    "- `colnum` : The number of the column we're cleaning\n",
    "\n",
    "It then runs the column of the `dataset` through the `char_check` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eng_clean(dataset,colnum):\n",
    "    tf_Dict = {}\n",
    "    for row in dataset:\n",
    "        name = row[colnum]\n",
    "        tf_Dict[name] = char_check(name)\n",
    "    return tf_Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our 'True/False Dictionaries' with these functions, resulting in two dictionaries whose keys represent the app names and whose definitions are all `True` or `False` based on whether they have too many foreign characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_tfDict = eng_clean(apple_clean,1)\n",
    "goog_tfDict=eng_clean(android_clean,0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Using our Dictionary to Trim our Dataset\n",
    "The next function is very similar to the `dictionary_trim()` function above, except its fourth paramter is used as a direct comparison rather than as a data point. The function `dictionary_slice()` takes the following parameters:\n",
    "\n",
    "-`dataset` : Dataset to be trimmed\n",
    "-`dictionary` : Dictionary to use as 'stencil' \n",
    "-`condition1` : Column to check against keys\n",
    "-`conditon2` : Column to check against definitions\n",
    "\n",
    "The major difference between `dictionary_slice()` and `dictionary_trim()` is that `condition2` isn't converted into a `float`, but compared as its current value. It then outputs the trimmed data to a new list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_slice(dataset, dictionary, condition1, condition2):\n",
    "    trimmed_data = []\n",
    "    added_list = []\n",
    "    for row in dataset:\n",
    "        name = row[condition1]\n",
    "        if name in dictionary and dictionary[name] == condition2 and name not in added_list:\n",
    "            trimmed_data.append(row)\n",
    "            added_list.append(name)\n",
    "    return trimmed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use this function on the `android_clean` and `apple_clean` lists, outputting lists that have only English-speaking apps that are the correct length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_cleaner = []\n",
    "android_cleaner = dictionary_slice(android_clean, goog_tfDict, 0, True)\n",
    "\n",
    "apple_cleaner = []\n",
    "apple_cleaner= dictionary_slice(apple_clean, apple_tfDict, 1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Purging Non-Free Apps\n",
    "Since we are only interested in the apps that are free, we can extract only those from the previous list that are free. To check to see what constitues 'Free' in both apps, we'll check a few lines of both datasets to see what how each set designates things as 'Free'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Pixel Draw - Number Art Coloring Book', 'ART_AND_DESIGN', '4.3', '967', '2.8M', '100,000+', 'Free', '0', 'Everyone', 'Art & Design;Creativity', 'June 20, 2018', '1.1', '4.4 and up'], ['Paper flowers instructions', 'ART_AND_DESIGN', '4.4', '167', '5.6M', '50,000+', 'Free', '0', 'Everyone', 'Art & Design', 'March 26, 2017', '1.0', '2.3 and up'], ['Smoke Effect Photo Maker - Smoke Editor', 'ART_AND_DESIGN', '3.8', '178', '19M', '50,000+', 'Free', '0', 'Everyone', 'Art & Design', 'April 26, 2018', '1.1', '4.0.3 and up']]\n",
      "[['420009108', 'Temple Run', '65921024', 'USD', '0.0', '1724546', '3842', '4.5', '4.0', '1.6.2', '9+', 'Games', '40', '5', '1', '1'], ['284035177', 'Pandora - Music & Radio', '130242560', 'USD', '0.0', '1126879', '3594', '4.0', '4.5', '8.4.1', '12+', 'Music', '37', '4', '1', '1'], ['429047995', 'Pinterest', '74778624', 'USD', '0.0', '1061624', '1814', '4.5', '4.0', '6.26', '12+', 'Social Networking', '37', '5', '27', '1']]\n"
     ]
    }
   ],
   "source": [
    "print(android_cleaner[3:6])\n",
    "print(apple_cleaner[3:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From that we can see that **Google Play Store** indicates free with the literal word '`Free`' which is represented by a `string`. The **App Store** is a little more traditional in its representation using a `float` value of `0.0`.\n",
    "\n",
    "Because they use two different variable types, we will make two different functions, one that checks for a `string` price and one that checks for a `float` price.\n",
    "\n",
    "The following two functions work as such: \n",
    "The `float_check()` function takes three parameters:\n",
    "\n",
    "- `datset` : The dataset we're checking\n",
    "- `pricecol` : The column the price is stored as a `float` value\n",
    "- `tarprice` : The target price as a `float` value\n",
    "\n",
    "It returns a list of rows with the `tarprice` value in the `pricecol` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_check(dataset, pricecol, tarprice):\n",
    "    tarprice_apps = []\n",
    "    price = 9898989898\n",
    "    for row in dataset:\n",
    "        price = float(row[pricecol])\n",
    "        if price == tarprice:\n",
    "            tarprice_apps.append(row)\n",
    "    return tarprice_apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `string_check()` function takes two parameters:\n",
    "\n",
    "- `dataset` : The dataset we're checking\n",
    "- `pricecol` : The column the price is held in\n",
    "- `tarstring` : The string we're checking against\n",
    "\n",
    "It returns a list of data whose price column matches the target string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_check(dataset,pricecol,tarstring):\n",
    "    tarprice_apps = []\n",
    "    for row in dataset:\n",
    "        if row[pricecol] == tarstring:\n",
    "            tarprice_apps.append(row)\n",
    "    return tarprice_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3220\n",
      "8863\n"
     ]
    }
   ],
   "source": [
    "apple_cleanest = float_check(apple_cleaner,4,0.0)\n",
    "android_cleanest = string_check(android_cleaner,6,'Free')\n",
    "\n",
    "print(len(apple_cleanest))\n",
    "print(len(android_cleanest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Analyzing the Clean Data\n",
    "\n",
    "Now that the data is stored in its cleanest form, it's time to take a look at the different available data points and determine what makes an app successful, and what kind of app could be theoretically successful.\n",
    "\n",
    "### Step 1: Determine the Relevant Data\n",
    "\n",
    "The first and most important thing we need to do is determine which columns of information are going to help us make a determination and which columns are extraneous. By checking the headers we printed out earlier, we can determine there are the following columns for each store: \n",
    "\n",
    "| Google Play Store | Apple Store      |\n",
    "|-------------------|------------------|\n",
    "| App               | id               |\n",
    "| Category          | track_name       |\n",
    "| Rating            | size_bytes       |\n",
    "| Reviews           | Currency         |\n",
    "| Size              | price            |\n",
    "| Installs          | rating_count_tot |\n",
    "| Type              | rating_count_ver |\n",
    "| Price             | user_rating      |\n",
    "| Content Rating    | user_rating_ver  |\n",
    "| Genres            | ver              |\n",
    "| Last Updated      | cont_rating      |\n",
    "| Current Ver       | prime_genre      |\n",
    "| Android Ver       | sup_devices.num  |\n",
    "|                   | ipadSc_urls.num  |\n",
    "|                   | lang.num         |\n",
    "|                   | vpp_lic          |\n",
    "\n",
    "\n",
    "The **Google Play Store** columns we're concerned about are going to be:\n",
    "- `Category`\n",
    "- `Genres`\n",
    "- `Rating`\n",
    "- `Reviews`\n",
    "- `Installs`\n",
    "\n",
    "The **App Store** columns we're concerned about are going to be:\n",
    "- `rating_count_tot`\n",
    "- `user_rating`\n",
    "- `prime_genre`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generating and Exploring Frequency Tables\n",
    "The following function `freq_table()` creates a frequency table, which is a table defining how often a particular type of data appears in a datasetin terms of a percentage of the dataset. \n",
    "\n",
    "The function `freq_table()` takes the following parameters: \n",
    "\n",
    "- `dataset` : The dataset from which we're generating a table\n",
    "- `index` : The column containing the types of data we'll generate frequencies of (e.g., genres) \n",
    "\n",
    "The function creates a dictionary `table` and pairs each unique `column` per `row` in the `dataset` paired with an integer value, which increases by one each time an additional instance of the `row[column]` value appears in the `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(dataset, index):\n",
    "    table = {}\n",
    "    for row in dataset:\n",
    "        column = row[index]\n",
    "        if column in table:\n",
    "            table[column]+=1\n",
    "        else:\n",
    "            table[column]=1\n",
    "    for row in table:\n",
    "        table[row] /= len(dataset)\n",
    "        table[row]*=100\n",
    "    return table\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `display_table()` function  takes the frequency table generated and displays it in descending order by transforming it into a list of tuples and then sorting them using the built-in function `sort()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Analyzing Categories\n",
    "\n",
    "Now that we have viable functions, we can start analyzing various categories in which we're interested. To start, let's take a look at the `Genres` and `Category` columns of the **Google Play Store** dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools : 8.450863138892023\n",
      "Entertainment : 6.070179397495204\n",
      "Education : 5.348076272142616\n",
      "Business : 4.592124562789123\n",
      "Productivity : 3.8925871601038025\n",
      "Lifestyle : 3.8925871601038025\n",
      "Finance : 3.7007785174320205\n",
      "Medical : 3.5315355974275078\n",
      "Sports : 3.463838429425702\n",
      "Personalization : 3.317161232088458\n",
      "Communication : 3.2381812027530184\n",
      "Action : 3.102786866749408\n",
      "Health & Fitness : 3.0802211440821394\n",
      "Photography : 2.944826808078529\n",
      "News & Magazines : 2.798149610741284\n",
      "Social : 2.6627552747376737\n",
      "Travel & Local : 2.324269434728647\n",
      "Shopping : 2.245289405393208\n",
      "Books & Reference : 2.1437436533904997\n",
      "Simulation : 2.042197901387792\n",
      "Dating : 1.8616721200496444\n",
      "Arcade : 1.8503892587160102\n",
      "Video Players & Editors : 1.771409229380571\n",
      "Casual : 1.7601263680469368\n",
      "Maps & Navigation : 1.399074805370642\n",
      "Food & Drink : 1.241114746699763\n",
      "Puzzle : 1.128286133363421\n",
      "Racing : 0.9928917973598104\n",
      "Role Playing : 0.9364774906916393\n",
      "Libraries & Demo : 0.9364774906916393\n",
      "Auto & Vehicles : 0.9251946293580051\n",
      "Strategy : 0.9026289066907368\n",
      "House & Home : 0.8236488773552973\n",
      "Weather : 0.8010831546880289\n",
      "Events : 0.7108202640189552\n",
      "Adventure : 0.6769716800180525\n",
      "Comics : 0.6092745120162473\n",
      "Beauty : 0.5979916506826132\n",
      "Art & Design : 0.5979916506826132\n",
      "Parenting : 0.4964458986799052\n",
      "Card : 0.4513144533453684\n",
      "Casino : 0.42874873067809993\n",
      "Trivia : 0.4174658693444658\n",
      "Educational;Education : 0.3949001466771973\n",
      "Board : 0.38361728534356315\n",
      "Educational : 0.37233442400992894\n",
      "Education;Education : 0.33848584000902626\n",
      "Word : 0.25950581067358686\n",
      "Casual;Pretend Play : 0.2369400880063184\n",
      "Music : 0.20309150400541578\n",
      "Racing;Action & Adventure : 0.16924292000451313\n",
      "Puzzle;Brain Games : 0.16924292000451313\n",
      "Entertainment;Music & Video : 0.16924292000451313\n",
      "Casual;Brain Games : 0.1353943360036105\n",
      "Casual;Action & Adventure : 0.1353943360036105\n",
      "Arcade;Action & Adventure : 0.1241114746699763\n",
      "Action;Action & Adventure : 0.10154575200270789\n",
      "Educational;Pretend Play : 0.09026289066907367\n",
      "Simulation;Action & Adventure : 0.07898002933543948\n",
      "Parenting;Education : 0.07898002933543948\n",
      "Entertainment;Brain Games : 0.07898002933543948\n",
      "Board;Brain Games : 0.07898002933543948\n",
      "Parenting;Music & Video : 0.06769716800180525\n",
      "Educational;Brain Games : 0.06769716800180525\n",
      "Casual;Creativity : 0.06769716800180525\n",
      "Art & Design;Creativity : 0.06769716800180525\n",
      "Education;Pretend Play : 0.05641430666817105\n",
      "Role Playing;Pretend Play : 0.045131445334536835\n",
      "Education;Creativity : 0.045131445334536835\n",
      "Role Playing;Action & Adventure : 0.033848584000902626\n",
      "Puzzle;Action & Adventure : 0.033848584000902626\n",
      "Entertainment;Creativity : 0.033848584000902626\n",
      "Entertainment;Action & Adventure : 0.033848584000902626\n",
      "Educational;Creativity : 0.033848584000902626\n",
      "Educational;Action & Adventure : 0.033848584000902626\n",
      "Education;Music & Video : 0.033848584000902626\n",
      "Education;Brain Games : 0.033848584000902626\n",
      "Education;Action & Adventure : 0.033848584000902626\n",
      "Adventure;Action & Adventure : 0.033848584000902626\n",
      "Video Players & Editors;Music & Video : 0.022565722667268417\n",
      "Sports;Action & Adventure : 0.022565722667268417\n",
      "Simulation;Pretend Play : 0.022565722667268417\n",
      "Puzzle;Creativity : 0.022565722667268417\n",
      "Music;Music & Video : 0.022565722667268417\n",
      "Entertainment;Pretend Play : 0.022565722667268417\n",
      "Casual;Education : 0.022565722667268417\n",
      "Board;Action & Adventure : 0.022565722667268417\n",
      "Video Players & Editors;Creativity : 0.011282861333634209\n",
      "Trivia;Education : 0.011282861333634209\n",
      "Travel & Local;Action & Adventure : 0.011282861333634209\n",
      "Tools;Education : 0.011282861333634209\n",
      "Strategy;Education : 0.011282861333634209\n",
      "Strategy;Creativity : 0.011282861333634209\n",
      "Strategy;Action & Adventure : 0.011282861333634209\n",
      "Simulation;Education : 0.011282861333634209\n",
      "Role Playing;Brain Games : 0.011282861333634209\n",
      "Racing;Pretend Play : 0.011282861333634209\n",
      "Puzzle;Education : 0.011282861333634209\n",
      "Parenting;Brain Games : 0.011282861333634209\n",
      "Music & Audio;Music & Video : 0.011282861333634209\n",
      "Lifestyle;Pretend Play : 0.011282861333634209\n",
      "Lifestyle;Education : 0.011282861333634209\n",
      "Health & Fitness;Education : 0.011282861333634209\n",
      "Health & Fitness;Action & Adventure : 0.011282861333634209\n",
      "Entertainment;Education : 0.011282861333634209\n",
      "Communication;Creativity : 0.011282861333634209\n",
      "Comics;Creativity : 0.011282861333634209\n",
      "Casual;Music & Video : 0.011282861333634209\n",
      "Card;Action & Adventure : 0.011282861333634209\n",
      "Books & Reference;Education : 0.011282861333634209\n",
      "Art & Design;Pretend Play : 0.011282861333634209\n",
      "Art & Design;Action & Adventure : 0.011282861333634209\n",
      "Arcade;Pretend Play : 0.011282861333634209\n",
      "Adventure;Education : 0.011282861333634209\n"
     ]
    }
   ],
   "source": [
    "display_table(android_cleanest,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAMILY : 18.898792733837304\n",
      "GAME : 9.725826469592688\n",
      "TOOLS : 8.462146000225657\n",
      "BUSINESS : 4.592124562789123\n",
      "LIFESTYLE : 3.9038700214374367\n",
      "PRODUCTIVITY : 3.8925871601038025\n",
      "FINANCE : 3.7007785174320205\n",
      "MEDICAL : 3.5315355974275078\n",
      "SPORTS : 3.396141261423897\n",
      "PERSONALIZATION : 3.317161232088458\n",
      "COMMUNICATION : 3.2381812027530184\n",
      "HEALTH_AND_FITNESS : 3.0802211440821394\n",
      "PHOTOGRAPHY : 2.944826808078529\n",
      "NEWS_AND_MAGAZINES : 2.798149610741284\n",
      "SOCIAL : 2.6627552747376737\n",
      "TRAVEL_AND_LOCAL : 2.335552296062281\n",
      "SHOPPING : 2.245289405393208\n",
      "BOOKS_AND_REFERENCE : 2.1437436533904997\n",
      "DATING : 1.8616721200496444\n",
      "VIDEO_PLAYERS : 1.7939749520478394\n",
      "MAPS_AND_NAVIGATION : 1.399074805370642\n",
      "FOOD_AND_DRINK : 1.241114746699763\n",
      "EDUCATION : 1.1621347173643235\n",
      "ENTERTAINMENT : 0.9590432133589079\n",
      "LIBRARIES_AND_DEMO : 0.9364774906916393\n",
      "AUTO_AND_VEHICLES : 0.9251946293580051\n",
      "HOUSE_AND_HOME : 0.8236488773552973\n",
      "WEATHER : 0.8010831546880289\n",
      "EVENTS : 0.7108202640189552\n",
      "PARENTING : 0.6544059573507841\n",
      "ART_AND_DESIGN : 0.6431230960171499\n",
      "COMICS : 0.6205573733498815\n",
      "BEAUTY : 0.5979916506826132\n"
     ]
    }
   ],
   "source": [
    "display_table(android_cleanest,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the types in the `Category` column have broader scopes than those in the `Genres` column, so we're going to stick with `Category` for the rest of our analases. \n",
    "\n",
    "From the `Category` frequency table we can see that, among the top ten most popular categories, only three are *Entertainment*-related, the others being more utilitarian in nature (e.g., `TOOLS`, `BUSINESS`, `PRODUCTIVITY`). We can therefore see that the **diversity** of apps skews more heavily towards practicality than entertainment on the **Google Play Store** but, remembering that we haven't looked at number of installs or ratings, they could be populated by low-download low-rated apps. Just because there are a lot of apps doesn't necessarily indicate that they're popular. We have to look further for that, but this gives us a nice baseline. Next let's take a look at the relative category int the **App Store**, `prime_genre`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games : 58.13664596273293\n",
      "Entertainment : 7.888198757763975\n",
      "Photo & Video : 4.968944099378882\n",
      "Education : 3.6645962732919255\n",
      "Social Networking : 3.291925465838509\n",
      "Shopping : 2.608695652173913\n",
      "Utilities : 2.515527950310559\n",
      "Sports : 2.142857142857143\n",
      "Music : 2.049689440993789\n",
      "Health & Fitness : 2.018633540372671\n",
      "Productivity : 1.7391304347826086\n",
      "Lifestyle : 1.5838509316770186\n",
      "News : 1.3354037267080745\n",
      "Travel : 1.2422360248447204\n",
      "Finance : 1.1180124223602486\n",
      "Weather : 0.8695652173913043\n",
      "Food & Drink : 0.8074534161490683\n",
      "Reference : 0.5590062111801243\n",
      "Business : 0.5279503105590062\n",
      "Book : 0.43478260869565216\n",
      "Navigation : 0.18633540372670807\n",
      "Medical : 0.18633540372670807\n",
      "Catalogs : 0.12422360248447205\n"
     ]
    }
   ],
   "source": [
    "display_table(apple_cleanest,11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In stark contrast to the **Google Play Store** we see here that ~58% of the available free apps in English in the **App Store** are *Games*, followed by another ~7.8% *Entertainment* and ~4.9% *Photo & Video*, which means over 70% of all available apps in the **App Store** that are free and English titled are dedicated to some form of entertainment and leisure.  Again, without knowing how many people are using these apps, we can't know for sure how popular they are, but this certainly gives us something useful to work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These large percentages of categories also gives us an indication of which markets might be *oversaturated* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Analyzing Popularity on the App Store\n",
    "\n",
    "The next thing to find out is which genre holds the most popular apps, which in the case of the App Store is most readily determined by using the `rating_count_tot` values, which represent the total number of user ratings, giving a rough indication of how many people use the app (and if they've rated it, they've probably generated ad revenue at that point, which is the goal).  \n",
    "\n",
    "The following function `ratings_table()` will be used to generate a dictionary where each `key` is the `genre` and each `definition` is the average number of ratings, giving us a general idea of how popular each genre is. It takes the following parameters:\n",
    "\n",
    "- `genreset` : A list of categories we're working with\n",
    "- `dataset` : The cleaned dataset\n",
    "- `typecol` : The column of the dataset whence the genre was extracted\n",
    "- `totratcol` : The column of the dataset where the total ratings value is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratings_table(genreset,dataset,typecol,totratcol):\n",
    "    rating_dict = {}\n",
    "    for genre in genreset:\n",
    "        total =0\n",
    "        len_genre = 0\n",
    "        for row in dataset:\n",
    "            genre_app = row[typecol]\n",
    "            if row[typecol] == genre:\n",
    "                total +=float(row[totratcol])\n",
    "                len_genre+=1\n",
    "        avg_ratnum = total/len_genre\n",
    "        rating_dict[genre]=avg_ratnum\n",
    "    return rating_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `extract_col()` below is how we're going to extract a quick genre table. It takes the following parameters: \n",
    "\n",
    "- `dataset` : The dataset we're extracting from\n",
    "- `colnum` : The column we're extracting\n",
    "- `header` : Whether or not to ignore the header (**False** indicates **NOT** ignoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_col(dataset, colnum, header=False):\n",
    "    extracted_col = []\n",
    "    if header == False:\n",
    "        for row in dataset:\n",
    "            extracted_col.append(row[colnum])\n",
    "        return extracted_col\n",
    "    else:\n",
    "        for row in dataset[1:]:\n",
    "            extracted_col.append(row[colnum])\n",
    "        return  extracted_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we use the built-in `sorted()` function in conjunction with a `lambda` function that lets us sort the dictionary by value rather than key, and a small `for` loop to print out a legible list of genres and their average number of ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigation 86090.33333333333\n",
      "Reference 74942.11111111111\n",
      "Social Networking 71548.34905660378\n",
      "Music 57326.530303030304\n",
      "Weather 52279.892857142855\n",
      "Book 39758.5\n",
      "Food & Drink 33333.92307692308\n",
      "Finance 31467.944444444445\n",
      "Photo & Video 28441.54375\n",
      "Travel 28243.8\n",
      "Shopping 26919.690476190477\n",
      "Health & Fitness 23298.015384615384\n",
      "Sports 23008.898550724636\n",
      "Games 22812.92467948718\n",
      "News 21248.023255813954\n",
      "Productivity 21028.410714285714\n",
      "Utilities 18684.456790123455\n",
      "Lifestyle 16485.764705882353\n",
      "Entertainment 14029.830708661417\n",
      "Business 7491.117647058823\n",
      "Education 7003.983050847458\n",
      "Catalogs 4004.0\n",
      "Medical 612.0\n"
     ]
    }
   ],
   "source": [
    "genre_table_apple = extract_col(apple_cleanest,11)\n",
    "apple_ratings = ratings_table(genre_table_apple,apple_cleanest, 11,5)\n",
    "apple_sorted_rats = sorted(apple_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for key in apple_sorted_rats:\n",
    "    print(key[0], key[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOPPED HERE #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringbased_table(genreset, dataset, typecol, installcol):\n",
    "    for category in genreset:\n",
    "        total = 0\n",
    "        len_category = 0\n",
    "        for row in dataset:\n",
    "            category_app = row[typecol]\n",
    "            if category_app == category:\n",
    "                installs = row[installcol]\n",
    "                installs = installs.replace(',','')\n",
    "                installs = installs.replace('+','')\n",
    "                installs = float(installs)\n",
    "                total += installs\n",
    "                len_category +=1\n",
    "        avg_installs = total/len_category\n",
    "        print(category + ': ')\n",
    "        print(avg_installs)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photo & Video:\n",
      "28441.54375\n",
      "Games:\n",
      "22812.92467948718\n",
      "Music:\n",
      "57326.530303030304\n",
      "Social Networking:\n",
      "43899.514285714286\n",
      "Reference:\n",
      "74942.11111111111\n",
      "Health & Fitness:\n",
      "23298.015384615384\n",
      "Weather:\n",
      "52279.892857142855\n",
      "Utilities:\n",
      "18684.456790123455\n",
      "Travel:\n",
      "28243.8\n",
      "Shopping:\n",
      "26919.690476190477\n",
      "News:\n",
      "21248.023255813954\n",
      "Navigation:\n",
      "86090.33333333333\n",
      "Lifestyle:\n",
      "16485.764705882353\n",
      "Entertainment:\n",
      "14029.830708661417\n",
      "Food & Drink:\n",
      "33333.92307692308\n",
      "Sports:\n",
      "23008.898550724636\n",
      "Book:\n",
      "39758.5\n",
      "Finance:\n",
      "31467.944444444445\n",
      "Education:\n",
      "7003.983050847458\n",
      "Productivity:\n",
      "21028.410714285714\n",
      "Business:\n",
      "7491.117647058823\n",
      "Catalogs:\n",
      "4004.0\n",
      "Medical:\n",
      "612.0\n"
     ]
    }
   ],
   "source": [
    "ratings_table(genre_table_apple, apple_cleanest, 11, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ART_AND_DESIGN: \n",
      "2021626.7857142857\n",
      "AUTO_AND_VEHICLES: \n",
      "647317.8170731707\n",
      "BEAUTY: \n",
      "513151.88679245283\n",
      "BOOKS_AND_REFERENCE: \n",
      "8767811.894736841\n",
      "BUSINESS: \n",
      "1712290.1474201474\n",
      "COMICS: \n",
      "817657.2727272727\n",
      "COMMUNICATION: \n",
      "38456119.167247385\n",
      "DATING: \n",
      "854028.8303030303\n",
      "EDUCATION: \n",
      "1833495.145631068\n",
      "ENTERTAINMENT: \n",
      "11640705.88235294\n",
      "EVENTS: \n",
      "253542.22222222222\n",
      "FINANCE: \n",
      "1387692.475609756\n",
      "FOOD_AND_DRINK: \n",
      "1924897.7363636363\n",
      "HEALTH_AND_FITNESS: \n",
      "4188821.9853479853\n",
      "HOUSE_AND_HOME: \n",
      "1331540.5616438356\n",
      "LIBRARIES_AND_DEMO: \n",
      "638503.734939759\n",
      "LIFESTYLE: \n",
      "1437816.2687861272\n",
      "GAME: \n",
      "15588015.603248259\n",
      "FAMILY: \n",
      "3697848.1731343283\n",
      "MEDICAL: \n",
      "120550.61980830671\n",
      "SOCIAL: \n",
      "23253652.127118643\n",
      "SHOPPING: \n",
      "7036877.311557789\n",
      "PHOTOGRAPHY: \n",
      "17840110.40229885\n",
      "SPORTS: \n",
      "3638640.1428571427\n",
      "TRAVEL_AND_LOCAL: \n",
      "13984077.710144928\n",
      "TOOLS: \n",
      "10801391.298666667\n",
      "PERSONALIZATION: \n",
      "5201482.6122448975\n",
      "PRODUCTIVITY: \n",
      "16787331.344927534\n",
      "PARENTING: \n",
      "542603.6206896552\n",
      "WEATHER: \n",
      "5074486.197183099\n",
      "VIDEO_PLAYERS: \n",
      "24727872.452830188\n",
      "NEWS_AND_MAGAZINES: \n",
      "9549178.467741935\n",
      "MAPS_AND_NAVIGATION: \n",
      "4056941.7741935486\n"
     ]
    }
   ],
   "source": [
    "stringbased_table(genre_table_google, android_cleanest,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
